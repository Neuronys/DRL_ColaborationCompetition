{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3 : Collaboration and Competition\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, we will use the **Tennis** Unity ML-Agents environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Model & Algorithm used\n",
    "\n",
    "### 1.1. Algorithm\n",
    "I've decided to use the DDPG algorithm and I've reused the multi-agent version of the code implemented for project 2 (https://github.com/Neuronys/DRL-ContinuousControl.git). the code for the model ('model.py') and the agent ('multi_agent.py') is highly inspired from:\n",
    "https://github.com/udacity/deep-reinforcement-learning/blob/55474449a112fa72323f484c4b7a498c8dc84be1/ddpg-bipedal/model.py and \n",
    "https://github.com/udacity/deep-reinforcement-learning/blob/55474449a112fa72323f484c4b7a498c8dc84be1/ddpg-bipedal/ddpg_agent.py\n",
    ", but adding the multi agent capability.\n",
    "\n",
    "My notebook is solving this project with 2 agents using their own DDPG algorithm, but sharing a common replay buffer to sample individually from it.\n",
    "\n",
    "### 1.2. Model\n",
    "Both Actor & Critic are implemented using deep neural networks with 2 hidden layers. I have experimented various architecture:\n",
    "- fc1 = 256 & fc2 = 128\n",
    "- fc1 = 256 & fc2 = 256\n",
    "- fc1 = 512 & fc2 = 256\n",
    "- fc1 = 512 & fc2 = 384\n",
    "\n",
    "And it appears that the last one (fc1 = 512 & fc2 = 384) is converging better and faster.\n",
    "As suggested in the Slack channel and tested already in the previous project, I have tried to add a Batch Normalization layer after the first layer, but it didn't improve the convergence. It was also suggested to use leaky_relu instead of rely for the Critic neural network, but I didn't notice improvement.\n",
    "\n",
    "### 1.3. Hyper parameters\n",
    "Convergence mainly came when I've started to tweak the hyper parameters:\n",
    "- I've doubled the size of the batch\n",
    "- I've drastically increased TAU \n",
    "- I've restored the learning rate of the Actor neural network to its orginal value (as I've changed it for project 2).\n",
    "\n",
    "The final configuration is:\n",
    "- BUFFER_SIZE = int(1e6)\n",
    "- BATCH_SIZE = 128\n",
    "- GAMMA = 0.99\n",
    "- TAU = 0.33\n",
    "- LR_ACTOR = 0.0001\n",
    "- LR_CRITIC = 0.0001\n",
    "- WEIGHT_DECAY = 0\n",
    "\n",
    "The Tennis environment is solved is less than 800 episodes, which seems a good result compared to others results on Slack. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Start the Environment\n",
    "\n",
    "Run the next code cell to install a few packages. This line will take a few minutes to run !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Watch for changes in any of the imported files\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from unityagents import UnityEnvironment\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from multi_agent import Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environment is already saved in the Workspace and can be accessed at the file path provided below.\n",
    "\n",
    "- **Mac**: `\"path/to/Tennis.app\"`\n",
    "- **Windows** (x86): `\"path/to/Tennis_Windows_x86/Tennis.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Tennis_Windows_x86_64/Tennis.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Tennis_Linux/Tennis.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Tennis_Linux/Tennis.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Tennis_Linux_NoVis/Tennis.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Tennis_Linux_NoVis/Tennis.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Tennis.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Tennis.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name='Tennis.app')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Examine the State and Action Spaces\n",
    "\n",
    "In this environment, two agents control rackets to bounce a ball over a net.\n",
    "- **Positive Rewards:** +0.1 if an agent hits the ball over the net.\n",
    "- **Negative Rewards:** -0.01 if an agent lets a ball hit the ground or hits the ball out of bounds.\n",
    "- **Observation Space:** 8 variables corresponding to the position and velocity of the ball and racket. Each agent receives its own, local observation.\n",
    "- **Action Space:** Two continuous actions are available: 1) movement toward (or away from) the net, and 2) jumping. \n",
    "\n",
    "So, the **Goal** of each agent is to keep the ball in play.\n",
    "\n",
    "The task is episodic, and in order to solve the environment, our agents must get an average score of +0.5 (over 100 consecutive episodes, after taking the maximum over both agents).\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Size of each action: 2\n",
      "There are 2 agents. Each observes a state with length: 24\n",
      "The state for the first agent looks like: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -6.65278625 -1.5\n",
      " -0.          0.          6.83172083  6.         -0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents \n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space\n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train the 2 agents\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scores(scores):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.plot(np.arange(len(scores)), scores)\n",
    "    plt.ylabel('Score')\n",
    "    plt.xlabel('Episode #')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-agent DDPG algo\n",
    "def ddpg_ma(n_episodes=2000):\n",
    "    scores = []\n",
    "    scores_deque = deque(maxlen=100)\n",
    "    \n",
    "    for e in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        agent.reset()\n",
    "        state = env_info.vector_observations            # get the current state\n",
    "\n",
    "        # Initialize the score for each agent\n",
    "        score = np.zeros(num_agents)\n",
    "        \n",
    "        # Keep track of the current timestep\n",
    "        t = 0\n",
    "        while True:\n",
    "            action = agent.act(state)          # select an action\n",
    "       \n",
    "            env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "            next_state = env_info.vector_observations   # get the next state\n",
    "            reward = env_info.rewards                   # get the reward\n",
    "            done = env_info.local_done                  # see if episode has finished\n",
    "            agent.step(state, action, reward, next_state, done) # take step with agent (including learning)\n",
    "            score += reward                                # update the score\n",
    "            state = next_state                             # roll over the state to next time step\n",
    "            \n",
    "            # Print the current mean score across all agents\n",
    "            print(f'\\rEpisode #{e}\\tTimestep #{t}'\n",
    "                  f'\\tScore = {np.mean(score):.5f}', end=\"\")\n",
    "            t += 1\n",
    "\n",
    "            if np.any(done):\n",
    "                break \n",
    "\n",
    "        # add up the rewards that each agent received\n",
    "        scores_sum = []\n",
    "        for i in range(num_agents):\n",
    "            scores_sum.append(np.sum(score[i]))\n",
    "        \n",
    "        # For this episode, take the max score over the two agent\n",
    "        max_score = np.max(scores_sum)\n",
    "\n",
    "        # Save the most recent score\n",
    "        scores.append(max_score)\n",
    "        scores_deque.append(max_score)\n",
    "        \n",
    "        # Record the mean score over the last 100 scores\n",
    "        mean_score = np.mean(scores_deque)\n",
    "\n",
    "        # Every 20 episodes, print the mean score over the last 100 episodes\n",
    "        if e % 20 == 0:\n",
    "            print(f'\\rEpisode #{e}'\n",
    "                  f'\\tAverage score (over the last 100 episodes) = {mean_score:.5f}')\n",
    "            \n",
    "        # Goal: Reach 0.5 (or more) over 100 consecutive episodes\n",
    "        if mean_score >= 0.5:\n",
    "            print(f'\\nTennis environment solved in {e:d} episodes!'\n",
    "                  f'\\tAverage score (over the last 100 episodes) = {mean_score:.5f}')\n",
    "            \n",
    "            torch.save(agent.actor_local.state_dict(), 'actor.pth')\n",
    "            torch.save(agent.critic_local.state_dict(), 'critic.pth')\n",
    "            break\n",
    "            \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode #20\tAverage score (over the last 100 episodes) = 0.00000\n",
      "Episode #40\tAverage score (over the last 100 episodes) = 0.00000\n",
      "Episode #60\tAverage score (over the last 100 episodes) = 0.00000\n",
      "Episode #80\tAverage score (over the last 100 episodes) = 0.00125\n",
      "Episode #100\tAverage score (over the last 100 episodes) = 0.00100\n",
      "Episode #120\tAverage score (over the last 100 episodes) = 0.00100\n",
      "Episode #140\tAverage score (over the last 100 episodes) = 0.00100\n",
      "Episode #160\tAverage score (over the last 100 episodes) = 0.00200\n",
      "Episode #180\tAverage score (over the last 100 episodes) = 0.00100\n",
      "Episode #200\tAverage score (over the last 100 episodes) = 0.00200\n",
      "Episode #220\tAverage score (over the last 100 episodes) = 0.00200\n",
      "Episode #240\tAverage score (over the last 100 episodes) = 0.00200\n",
      "Episode #260\tAverage score (over the last 100 episodes) = 0.00490\n",
      "Episode #280\tAverage score (over the last 100 episodes) = 0.01150\n",
      "Episode #300\tAverage score (over the last 100 episodes) = 0.01890\n",
      "Episode #320\tAverage score (over the last 100 episodes) = 0.02850\n",
      "Episode #340\tAverage score (over the last 100 episodes) = 0.03830\n",
      "Episode #360\tAverage score (over the last 100 episodes) = 0.04680\n",
      "Episode #380\tAverage score (over the last 100 episodes) = 0.06000\n",
      "Episode #400\tAverage score (over the last 100 episodes) = 0.06860\n",
      "Episode #420\tAverage score (over the last 100 episodes) = 0.08080\n",
      "Episode #440\tAverage score (over the last 100 episodes) = 0.09370\n",
      "Episode #460\tAverage score (over the last 100 episodes) = 0.12100\n",
      "Episode #480\tAverage score (over the last 100 episodes) = 0.16010\n",
      "Episode #500\tAverage score (over the last 100 episodes) = 0.21590\n",
      "Episode #520\tAverage score (over the last 100 episodes) = 0.24390\n",
      "Episode #540\tAverage score (over the last 100 episodes) = 0.28410\n",
      "Episode #560\tAverage score (over the last 100 episodes) = 0.29340\n",
      "Episode #580\tAverage score (over the last 100 episodes) = 0.26950\n",
      "Episode #600\tAverage score (over the last 100 episodes) = 0.28770\n",
      "Episode #620\tAverage score (over the last 100 episodes) = 0.30970\n",
      "Episode #640\tAverage score (over the last 100 episodes) = 0.27670\n",
      "Episode #660\tAverage score (over the last 100 episodes) = 0.29940\n",
      "Episode #680\tAverage score (over the last 100 episodes) = 0.33930\n",
      "Episode #700\tAverage score (over the last 100 episodes) = 0.32510\n",
      "Episode #720\tAverage score (over the last 100 episodes) = 0.37810\n",
      "Episode #740\tAverage score (over the last 100 episodes) = 0.47210\n",
      "Episode #760\tAverage score (over the last 100 episodes) = 0.48120\n",
      "Episode #765\tTimestep #639\tScore = 1.59500\n",
      "Tennis environment solved in 765 episodes!\tAverage score (over the last 100 episodes) = 0.51020\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the agent\n",
    "agent = Agent(state_size=state_size, action_size=action_size, num_agents=num_agents, random_seed=22)\n",
    "# Train the DDPG agent\n",
    "scores = ddpg_ma(n_episodes=1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Plot the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the result\n",
    "plot_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Future work (already suggested in project 2)\n",
    "I've focussed on DDPG but there are DDPG improvements to try, such as D3PG and D4PG, A3C and PPO:\n",
    "- In the Slack channel, some students have reported great results using PPO instead of DDPG.\n",
    "- In this paper written by Barth-Maron et al 2018 D4PG has achieved state of the art results on continuous control problems.\n",
    "\n",
    "However there is still room for improvement on the DDPG algorithm:\n",
    "- use priority in the Replay Buffer\n",
    "- adjust the Ornstein-Uhlenbeck noise level"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
